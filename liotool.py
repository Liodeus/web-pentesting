#!/usr/bin/env python3

from datetime import datetime
import validators
import argparse
import time
import os

WEB_ANALYZE_TECHNO_PATH = "/home/liodeus/technologies.json"
LINKFINDER_PATH = "/home/liodeus/Documents/bugbounty/js/LinkFinder/linkfinder.py"
SECRETFINDER_PATH = "/home/liodeus/Documents/bugbounty/js/secretfinder/SecretFinder.py"


def start_print(tool_name):
	print("*******************************")
	print(f"\t START {tool_name}")
	print("*******************************")


def end_print(tool_name):
	print("*******************************")
	print(f"\t END {tool_name}")
	print("*******************************")


def detect_techno(url, path):
	start_print("TECHNOLOGIE")
	os.system(f"whatweb {url} > {path}/whatweb.out")
	os.system(f"webanalyze -host {url} -silent -apps {WEB_ANALYZE_TECHNO_PATH} > {path}/webanalyze.out")
	end_print("TECHNOLOGIE")


def launch_spider(url, domain, path):
	start_print("GOSPIDER")
	os.system(f"gospider -a -r --sitemap -q -d 3 -s {url} -o {path}/")
	end_print("GOSPIDER")


def launch_gauplus(domain, path):
	start_print("GAUPLUS")
	# Get more results if some where missings
	os.system(f"gauplus --random-agent -b css,jpg,png,gif,svg,ico,woff,woff2,pdf,ttf,otf,jpeg,JPG,mp4,mp3,avi,eot -o {path}/gauplus {domain}")
	end_print("GAUPLUS")


def merge_files(domain, path):
	start_print("MERGING")
	os.system(f"cat {path}/{domain.replace('.', '_')} {path}/gauplus > {path}/merge")
	end_print("MERGING")


def parse_data_merge_gospider_gauplus(domain, path):
	start_print("PARSING")
	
	# Get subdomains
	os.system(f"cat {path}/merge | grep " + "'\[subdomains\]'" + f" | awk -F'- ' '{{print $2}}' > {path}/gospider.subdomains")

	# Remove subdomains
	os.system(f"cat {path}/merge | grep -v " + "'\[subdomains\]'" + f" > {path}/gospider_subdomain_remove")

	# Get forms
	os.system(f"cat {path}/gospider_subdomain_remove | grep " + "'\[form\]'" + f" | awk -F'- ' '{{print $2}}' > {path}/gospider.forms")
	# Remove forms
	os.system(f"cat {path}/gospider_subdomain_remove | grep -v " + "'\[form\]'" + f" > {path}/gospider_forms_remove")

	# Get href, javascript, linkfinder
	os.system(f"cat {path}/gospider_forms_remove | grep -E " + "'\[href|javascript|linkfinder\]'" + f" | awk -F'- ' '{{print $2}}' > {path}/gospider_href_js_link_temp 2>/dev/null")
	# Remove href, javascript, linkfinder
	os.system(f"cat {path}/gospider_forms_remove | grep -Ev " + "'\[href|javascript|linkfinder\]'" + f" > {path}/gospider_href_js_link_remove")
	
	# Get url
	os.system(f"cat {path}/gospider_href_js_link_remove | grep " + "'\[url\]'" + f" | awk  -F'] -' '{{print $3}}' > {path}/gospider_url_temp 2>/dev/null")
	# Remove url
	os.system(f"cat {path}/gospider_href_js_link_remove | grep -v " + "'\[url\]'" + f" > {path}/gospider_url_remove")

	# Merge href, javascript, linkfinder, url and all
	os.system(f"cat {path}/gospider_url_temp {path}/gospider_href_js_link_temp {path}/gospider_url_remove > {path}/merge_temp")

	# Sort, remove duplicates
	os.system(f"cat {path}/merge_temp | uro | sort -u > {path}/out_temp")
	# Remove domain not in scope
	os.system(f"cat {path}/out_temp| grep -E '{domain.split('.')[0]}" + "\.'" + f"{domain.split('.')[1]} > {path}/gospider.out")

	# Get .js files
	os.system(f"cat {path}/gospider.out | grep '\.js' | grep -v '\.json' > {path}/gospider.js")

	end_print("PARSING")


def remove_unused_files_gospider_gauplus(domain, path):
	start_print("REMOVING")
	os.system(f"rm  {path}/out_temp {path}/merge {path}/merge_temp {path}/gauplus {path}/{domain.replace('.', '_')} {path}/gospider_href_js_link_remove {path}/gospider_href_js_link_temp {path}/gospider_url_temp {path}/gospider_url_remove {path}/gospider_subdomain_remove {path}/gospider_forms_remove {path}/{domain}.gospider_href_js_link_remove {path}/{domain}.gospider_url_remove {path}/{domain}.gauplus 2>/dev/null")
	end_print("REMOVING")


def launch_js(url, domain, path):
	# Find more js path
	os.system(f"echo {url} | subjs -c 40 | grep -E '{domain.split('.')[0]}" + "\.'" + f"{domain.split('.')[1]} > {path}/subjs.out")
	# Merge js files and remove duplicate
	os.system(f"cat {path}/subjs.out {path}/gospider.js | sort -u > {path}/js.out")

	# Find new path/links in js files
	os.system(f"for line in $(cat {path}/js.out); do python3 {LINKFINDER_PATH} -i $line -o cli >> {path}/linkfinder.out; done")
	# Get http/https path (URL)
	os.system(f"cat {path}/linkfinder.out| sort -u | grep -E 'https?://' > {path}/new_urls.out")
	# Remove URLs from the path
	os.system(f"cat {path}/linkfinder.out| sort -u | grep -Ev 'https?://' > {path}/linkfinder_without_urls.out")

	# Add all the new path to new URL
	with open(f"{path}/new_path.out", 'w') as file:
		with open(f"{path}/linkfinder_without_urls.out") as lines:
			for line in lines:
				line = line.strip()
				first_char = line[0]

				# If first char is a point, remove the point -> url/line
				if first_char == '.':
					file.write(f"{url}/{line[1:]}")
				# If first char is a slash -> append the path to the url
				elif first_char == '/':
					file.write(f"{url}{line}")
				# Else append the path a slash and the path
				else:
					file.write(f"{url}/{line}")

	os.system(f"for line in $(cat {path}/js.out); do python3 {SECRETFINDER_PATH} -i $line -o cli >> {path}/secretfinder.out; done")



if __name__ == '__main__':
	parser = argparse.ArgumentParser()
	parser.add_argument("-u", "--url", help="URL to search", type=str, required=True)
	parser.add_argument("-o", "--out", help="Output directory", type=str)
	args = parser.parse_args()
	url = args.url

	# Validate URL
	if validators.url(url):
		# Remove the slash at the end of url 
		# https://test.com/ -> https://test.com
		# https://test.com/test/test/test.php -> https://test.com
		now = datetime.now()
		domain = url.split('/')[2]
		dir_name =  now.strftime("%b_%d_%Y_%H_%M_%S_") + domain
		path = os.getcwd()

		if args.out:
			path = args.out

		path_arg = f"{path}/{dir_name}"

		try:
			os.makedirs(path_arg, exist_ok=False)
		except FileExistsError:
			print("Directory already exists")
			exit()

		# Starting commands
		detect_techno(url, path_arg)
		launch_spider(url, domain, path_arg)
		launch_gauplus(domain, path_arg)
		merge_files(domain, path_arg)
		parse_data_merge_gospider_gauplus(domain, path_arg)
		remove_unused_files_gospider_gauplus(domain, path_arg)
		launch_js(url, domain, path_arg)
	else:
		print("Need a valid URL")
		exit()
